# Prometheus Stack Custom Values
# Configured for dev-system namespace with existing infrastructure

## Global Settings
global:
  resolve_timeout: 5m

## Prometheus Configuration
prometheus:
  service:
    port: 80
    targetPort: 9090
  prometheusSpec:
    # Enable remote write receiver for k6 integration
    enableRemoteWriteReceiver: true
    enableFeatures:
      - remote-write-receiver
    retention: 15d
    retentionSize: 10GB
    resources:
      requests:
        memory: 400Mi
        cpu: 100m
      limits:
        memory: 800Mi
        cpu: 200m
    # Storage disabled for temporary monitoring
    # storageSpec: null
    # Enable service discovery for all namespaces
    serviceMonitorNamespaceSelector: {}
    serviceMonitorSelector: {}
    podMonitorNamespaceSelector: {}
    podMonitorSelector: {}
    ruleNamespaceSelector: {}
    ruleSelector: {}
    # ì»¤ìŠ¤í…€ ì•Œë¦¼ ê·œì¹™ ë¡œë”©
    additionalPrometheusRulesMap:
      eks-infrastructure-rules:
        groups:
          - name: infrastructure.critical
            interval: 30s
            rules:
              - alert: NodeDown
                expr: up{job="node-exporter"} == 0
                for: 1m
                labels:
                  severity: critical
                  category: infrastructure
                  priority: P0
                annotations:
                  summary: 'EKS ë…¸ë“œê°€ ë‹¤ìš´ë˜ì—ˆìŠµë‹ˆë‹¤'
                  description: 'ë…¸ë“œ {{ $labels.instance }}ê°€ 1ë¶„ ì´ìƒ ì‘ë‹µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.'

              - alert: NodeMemoryCritical
                expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 95
                for: 2m
                labels:
                  severity: critical
                  category: infrastructure
                  priority: P0
                annotations:
                  summary: 'ë…¸ë“œ ë©”ëª¨ë¦¬ê°€ ìœ„í—˜ ìˆ˜ì¤€ì…ë‹ˆë‹¤'
                  description: 'ë…¸ë“œ {{ $labels.instance }}ì˜ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ì´ {{ $value }}%ì…ë‹ˆë‹¤.'

              - alert: NodeDiskSpaceCritical
                expr: (1 - (node_filesystem_avail_bytes{fstype!="tmpfs"} / node_filesystem_size_bytes{fstype!="tmpfs"})) * 100 > 90
                for: 5m
                labels:
                  severity: critical
                  category: infrastructure
                  priority: P0
                annotations:
                  summary: 'ë…¸ë“œ ë””ìŠ¤í¬ ê³µê°„ì´ ë¶€ì¡±í•©ë‹ˆë‹¤'
                  description: 'ë…¸ë“œ {{ $labels.instance }}ì˜ {{ $labels.mountpoint }} ì‚¬ìš©ë¥ ì´ {{ $value }}%ì…ë‹ˆë‹¤.'

          - name: application.critical
            interval: 30s
            rules:
              - alert: PodCrashLooping
                expr: rate(kube_pod_container_status_restarts_total[1h]) > 2
                for: 5m
                labels:
                  severity: critical
                  category: application
                  priority: P1
                annotations:
                  summary: 'Podê°€ í¬ë˜ì‹œ ë£¨í”„ ìƒíƒœì…ë‹ˆë‹¤'
                  description: '{{ $labels.namespace }}/{{ $labels.pod }} Podê°€ 1ì‹œê°„ì— 2íšŒ ì´ìƒ ì¬ì‹œì‘ë˜ê³  ìˆìŠµë‹ˆë‹¤.'

          - name: resource.warning
            interval: 60s
            rules:
              - alert: NodeCPUHigh
                expr: (100 - (avg by (instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)) > 80
                for: 10m
                labels:
                  severity: warning
                  category: resource
                  priority: P2
                annotations:
                  summary: 'ë…¸ë“œ CPU ì‚¬ìš©ë¥ ì´ ë†’ìŠµë‹ˆë‹¤'
                  description: 'ë…¸ë“œ {{ $labels.instance }}ì˜ CPU ì‚¬ìš©ë¥ ì´ {{ $value }}%ì…ë‹ˆë‹¤.'

              - alert: NodeMemoryHigh
                expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 80
                for: 10m
                labels:
                  severity: warning
                  category: resource
                  priority: P2
                annotations:
                  summary: 'ë…¸ë“œ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ì´ ë†’ìŠµë‹ˆë‹¤'
                  description: 'ë…¸ë“œ {{ $labels.instance }}ì˜ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ì´ {{ $value }}%ì…ë‹ˆë‹¤.'

    # Additional Scrape Configs for custom applications
    additionalScrapeConfigs:
      # Kafka JMX metrics (if exposed)
      - job_name: 'kafka-jmx'
        static_configs:
          - targets: ['kafka-0.kafka-headless.dev-system:9999']
        scrape_interval: 30s
        metrics_path: /metrics

      # Redis metrics (if redis_exporter is deployed)
      - job_name: 'redis'
        static_configs:
          - targets: ['redis-exporter.dev-system:9121']
        scrape_interval: 30s

      # Custom application metrics
      - job_name: 'kubernetes-services'
        kubernetes_sd_configs:
          - role: service
            namespaces:
              names:
                - dev-system
        relabel_configs:
          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape]
            action: keep
            regex: true

## Grafana Configuration
grafana:
  enabled: true
  adminUser: admin
  adminPassword: grafana163

  # Resource limits
  resources:
    requests:
      memory: 128Mi
      cpu: 100m
    limits:
      memory: 256Mi
      cpu: 200m

  # Persistence disabled (as requested)
  persistence:
    enabled: false

  # Grafana configuration
  grafana.ini:
    server:
      domain: grafana.dev-cluster.local
      root_url: http://grafana.dev-cluster.local
    security:
      cookie_secure: false
    users:
      allow_sign_up: false
      auto_assign_org: true
      auto_assign_org_role: Viewer
      default_theme: dark
    auth:
      disable_login_form: false
    analytics:
      check_for_updates: false
      reporting_enabled: false

  # Additional data sources
  additionalDataSources:
    - name: PostgreSQL
      type: postgres
      url: postgres:5432
      database: postgres
      user: postgres
      jsonData:
        sslmode: disable
        postgresVersion: 1300
      secureJsonData:
        password: example
      isDefault: false
      editable: true
    - name: Airflow PostgreSQL
      type: postgres
      url: postgres:5432
      database: airflow
      user: postgres
      jsonData:
        sslmode: disable
        postgresVersion: 1300
      secureJsonData:
        password: example
      isDefault: false
      editable: true

  # Dashboard Providers Configuration
  dashboardProviders:
    dashboardproviders.yaml:
      apiVersion: 1
      providers:
        - name: 'kubernetes-monitoring'
          orgId: 1
          folder: 'Kubernetes Monitoring'
          folderUid: 'k8s-monitoring'
          type: file
          disableDeletion: false
          editable: true
          updateIntervalSeconds: 10
          allowUiUpdates: true
          options:
            path: /var/lib/grafana/dashboards/kubernetes-monitoring
        - name: 'application-monitoring'
          orgId: 1
          folder: 'Application Monitoring'
          folderUid: 'app-monitoring'
          type: file
          disableDeletion: false
          editable: true
          updateIntervalSeconds: 10
          allowUiUpdates: true
          options:
            path: /var/lib/grafana/dashboards/application-monitoring

  # ConfigMapìœ¼ë¡œë¶€í„° ëŒ€ì‹œë³´ë“œ ìë™ ë¡œë”© (sidecar)
  sidecar:
    dashboards:
      enabled: true
      label: grafana_dashboard
      labelValue: '1'
      folder: /tmp/dashboards
      folderAnnotation: grafana_folder
      searchNamespace: dev-system
      provider:
        disableDelete: false
        allowUiUpdates: true
        foldersFromFilesStructure: true

  # Dashboard Files - ì»¤ë®¤ë‹ˆí‹° ëŒ€ì‹œë³´ë“œì™€ ì»¤ìŠ¤í…€ ëŒ€ì‹œë³´ë“œ ì¡°í•©
  dashboards:
    kubernetes-monitoring:
      # Node Exporter ê¸°ë³¸ ëŒ€ì‹œë³´ë“œ (ê²€ì¦ëœ ì»¤ë®¤ë‹ˆí‹° ë²„ì „)
      node-exporter-full:
        gnetId: 1860
        revision: 31
        datasource: Prometheus
      # Kubernetes Cluster Monitoring
      kubernetes-cluster-monitoring:
        gnetId: 7249
        revision: 1
        datasource: Prometheus
    application-monitoring:
      # Redis Dashboard
      redis-overview:
        gnetId: 763
        revision: 4
        datasource: Prometheus
      # PostgreSQL Dashboard
      postgresql-overview:
        gnetId: 9628
        revision: 7
        datasource: Prometheus

## AlertManager Configuration
alertmanager:
  enabled: true
  service:
    port: 80
    targetPort: 9093
    annotations:
      alb.ingress.kubernetes.io/healthcheck-path: /-/healthy
    # Disable reloader port completely
    additionalPorts: []
  serviceMonitor:
    # Disable service monitor on reloader port
    additionalEndpoints: []
  alertmanagerSpec:
    resources:
      requests:
        memory: 200Mi
        cpu: 50m
      limits:
        memory: 400Mi
        cpu: 100m
    # Storage disabled for temporary monitoring
    # storage: null

    # AlertManager ì„¤ì • íŒŒì¼ ë¡œë”©
    configSecret: alertmanager-config

    # ì•Œë¦¼ ë³´ì¡´ ê¸°ê°„
    retention: 120h

    # ì™¸ë¶€ URL (ALB í†µí•´ ì ‘ê·¼ ì‹œ)
    externalUrl: http://alertmanager.dev-cluster.local

  # AlertManager ì„¤ì • (ConfigMapìœ¼ë¡œ ê´€ë¦¬)
  config:
    global:
      smtp_smarthost: 'localhost:587'
      smtp_from: 'alerts@dev-cluster.local'
      resolve_timeout: 5m

    route:
      group_by: ['alertname', 'cluster', 'service']
      group_wait: 10s
      group_interval: 5m
      repeat_interval: 2h
      receiver: 'web.hook.default'

      routes:
        # P0: ì¸í”„ë¼ í¬ë¦¬í‹°ì»¬ (ì¦‰ì‹œ)
        - match:
            severity: critical
            category: infrastructure
          receiver: 'infrastructure-critical'
          group_wait: 0s
          repeat_interval: 5m

        # P1: ì• í”Œë¦¬ì¼€ì´ì…˜ í¬ë¦¬í‹°ì»¬
        - match:
            severity: critical
            category: application
          receiver: 'application-critical'
          group_wait: 30s
          repeat_interval: 10m

        # P2: ë¦¬ì†ŒìŠ¤ ê²½ê³ 
        - match:
            severity: warning
            category: resource
          receiver: 'resource-warning'
          group_wait: 5m
          repeat_interval: 1h

    receivers:
      # ê¸°ë³¸ ìˆ˜ì‹ ì (ì›¹í›…)
      - name: 'web.hook.default'
        webhook_configs:
          - url: 'http://localhost:5001/webhook'
            send_resolved: true

      # P0: ì¸í”„ë¼ í¬ë¦¬í‹°ì»¬ (Slack ì•Œë¦¼)
      - name: 'infrastructure-critical'
        slack_configs:
          - api_url: 'https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK'
            channel: '#ops-critical'
            username: 'AlertManager'
            title: 'ğŸš¨ [P0-CRITICAL] EKS í´ëŸ¬ìŠ¤í„° ì¸í”„ë¼ ì¥ì• '
            text: |
              *ì•Œë¦¼:* {{ range .Alerts }}{{ .Annotations.summary }}{{ end }}
              *í´ëŸ¬ìŠ¤í„°:* {{ .GroupLabels.cluster }}
              *ì‹œê°„:* {{ .CommonAnnotations.startsAt }}
              *ì¦‰ì‹œ í™•ì¸ í•„ìš”* - í´ëŸ¬ìŠ¤í„° ê°€ìš©ì„±ì— ì˜í–¥
            send_resolved: true

      # P1: ì• í”Œë¦¬ì¼€ì´ì…˜ í¬ë¦¬í‹°ì»¬
      - name: 'application-critical'
        slack_configs:
          - api_url: 'https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK'
            channel: '#app-alerts'
            username: 'AlertManager'
            title: 'âš ï¸ [P1-CRITICAL] í•µì‹¬ ì„œë¹„ìŠ¤ ì¥ì• '
            text: |
              *ì„œë¹„ìŠ¤:* {{ .GroupLabels.service }}
              *ì•Œë¦¼:* {{ range .Alerts }}{{ .Annotations.summary }}{{ end }}
              *ëŒ€ì‘:* 15ë¶„ ì´ë‚´ í™•ì¸ í•„ìš”
            send_resolved: true

      # P2: ë¦¬ì†ŒìŠ¤ ê²½ê³ 
      - name: 'resource-warning'
        slack_configs:
          - api_url: 'https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK'
            channel: '#monitoring'
            username: 'AlertManager'
            title: 'â— [P2-WARNING] ë¦¬ì†ŒìŠ¤ ì„ê³„ê°’ ê²½ê³ '
            text: |
              *ë…¸ë“œ:* {{ .GroupLabels.instance }}
              *ë©”íŠ¸ë¦­:* {{ .GroupLabels.alertname }}
              *ê¶Œì¥:* 30ë¶„ ì´ë‚´ í™•ì¸ ë° ìŠ¤ì¼€ì¼ë§ ê²€í† 
            send_resolved: true

    # ì–µì œ ê·œì¹™ (ì¤‘ë³µ ì•Œë¦¼ ë°©ì§€)
    inhibit_rules:
      # ë…¸ë“œ ë‹¤ìš´ ì‹œ í•´ë‹¹ ë…¸ë“œì˜ ë‹¤ë¥¸ ì•Œë¦¼ ì–µì œ
      - source_match:
          severity: 'critical'
          alertname: 'NodeDown'
        target_match:
          severity: 'warning'
        equal: ['instance']

## Node Exporter Configuration
nodeExporter:
  enabled: true

## kube-state-metrics Configuration
kubeStateMetrics:
  enabled: true

## Prometheus Operator Configuration
prometheusOperator:
  enabled: true
  resources:
    requests:
      memory: 100Mi
      cpu: 50m
    limits:
      memory: 200Mi
      cpu: 100m

## Default Rules (Kubernetes monitoring)
defaultRules:
  create: true
  rules:
    alertmanager: true
    etcd: true
    configReloaders: true
    general: true
    k8s: true
    kubeApiserverAvailability: true
    kubeApiserverBurnrate: true
    kubeApiserverHistogram: true
    kubeApiserverSlos: true
    kubelet: true
    kubeProxy: true
    kubePrometheusGeneral: true
    kubePrometheusNodeRecording: true
    kubernetesApps: true
    kubernetesResources: true
    kubernetesStorage: true
    kubernetesSystem: true
    node: true
    nodeExporterAlerting: true
    nodeExporterRecording: true
    prometheus: true
    prometheusOperator: true
